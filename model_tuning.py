# -*- coding: utf-8 -*-
"""Model-Tuning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g3O4xa9ojLORMvry_VSJaUED9HLKuVqv
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

data= sns.load_dataset('iris')

data.head()

data.duplicated()  #to check whether is any duplicate values

duplicates = data[data.duplicated(keep=False)]
print(duplicates)  #this command is used to find which rows are duplicates in the whole data...

data['species'].unique()  #it will print all the unique data of species columns

#now data is already cleaned and pre processed , we will now split input and output feature....
x= data.drop('species',axis=1)
y=data['species']

#now we will perform train test split
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.33,random_state=42)

#importing model
from sklearn.neighbors import KNeighborsClassifier

#building a model
knn_model= KNeighborsClassifier(n_neighbors=25)

#training to the model
knn_model.fit(x_train,y_train)

knn_model.score(x_test,y_test)

y_pred= knn_model.predict(x_test)

from sklearn.metrics import accuracy_score,f1_score,classification_report

accuracy_score(y_pred,y_test)
#for n=5 it is giving 98% but if n=25 then accuracy is 100%
#it means when we change the parameter of model then performance of model also varies..

print(classification_report(y_pred,y_test))

from sklearn.svm import SVC

svm_model= SVC(C=10,kernel='linear',gamma='auto')

svm_model.fit(x_train,y_train)

svm_model.score(x_test,y_test)

#so when we change the value of c and kernel then also our prediction
#got change...

#now our task is to find the best permuation(arrangement) of parameter which can give us best accuracy for our model..
#This process is known as Model Tuning (HyperParameter Tuning)
#Model tuning can be done in 3 ways: Manual , GridSearchCV,RandomSearchCV

#now lets use grid search cv
from sklearn.model_selection import GridSearchCV

classifier= GridSearchCV((svm_model),{
    'C':[1,10,20,30],
    'kernel':['rbf','linear']
},cv=5,return_train_score=False)

classifier.fit(x,y)

#now model tuning is done and we have to see the result which parameters are best
classifier.cv_results_

df= pd.DataFrame(classifier.cv_results_)

df

df[['param_C',	'param_kernel','params','mean_test_score']]

#now hyper parameter or model tuning is done for our svm model using grid search cv.

#now we will do same for knn model.. So lets go

#third method is random search cv..This is done when our permutation of
#hyper parameter is too high(for eg. above 1000) so our system get hang or get very slow so to
#overcome from this problem we use random search cv..

from sklearn.model_selection import RandomizedSearchCV

classifier_r = RandomizedSearchCV((svm_model),{
    'C':[1,10,20,30],
    'kernel':['rbf','linear']
},n_iter= 4, cv=5,return_train_score=False)

classifier_r.fit(x,y)

results= pd.DataFrame(classifier_r.cv_results_)

results[['param_C',	'param_kernel','params','mean_test_score']]

